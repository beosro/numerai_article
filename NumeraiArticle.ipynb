{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, the idea of the Numerai tournament is to let data scientists use machine learning techniques to earn money by  creating predictions for Numerai’s hedge fund.\n",
    "\n",
    "The machine learning techniques can be neural networks, random forests, support vector machines, etc… . In this article I will focus on using neural networks. These neural networks will be programmed and trained using Python, Keras and scikit-learn (sklearn).\n",
    "\n",
    "In addition to creating predictions for the regular tournament, it is also possible use our predictions to participate in a ‘staked’ tournament. We can stake the cryptocurrency numeraire (NMR) on our predictions in order to earn additional money. In this article, though, I  will only cover how to create predictions for the regular tournament."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this article the following programs and libraries need to be installed:\n",
    "\n",
    "* Python 3 (from Anaconda)\n",
    "* Keras\n",
    "* scikit-learn\n",
    "* Pandas\n",
    "* Numpy\n",
    "* Jupyter Notebook\n",
    "\n",
    "We will also need to have an account on Numerai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading the current datasets, we can have a look in the unzipped directory. Of relevance are the two CSV files:\n",
    "* `numerai_training_data.csv`\n",
    "* `numerai_tournament_data.csv`\n",
    "\n",
    "The first file contains the training data and the second file the tournament data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('numerai_training_data.csv', header=0)\n",
    "tournament_data = pd.read_csv('numerai_tournament_data.csv', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let’s have a quick look at the data in the files using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>era</th>\n",
       "      <th>data_type</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature42</th>\n",
       "      <th>feature43</th>\n",
       "      <th>feature44</th>\n",
       "      <th>feature45</th>\n",
       "      <th>feature46</th>\n",
       "      <th>feature47</th>\n",
       "      <th>feature48</th>\n",
       "      <th>feature49</th>\n",
       "      <th>feature50</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n221973c37ed247a</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.55098</td>\n",
       "      <td>0.42673</td>\n",
       "      <td>0.40180</td>\n",
       "      <td>0.44622</td>\n",
       "      <td>0.68562</td>\n",
       "      <td>0.45346</td>\n",
       "      <td>0.24763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.55924</td>\n",
       "      <td>0.64714</td>\n",
       "      <td>0.62358</td>\n",
       "      <td>0.40199</td>\n",
       "      <td>0.51210</td>\n",
       "      <td>0.42287</td>\n",
       "      <td>0.33241</td>\n",
       "      <td>0.54669</td>\n",
       "      <td>0.55408</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n435a06426e694b7</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.32694</td>\n",
       "      <td>0.37829</td>\n",
       "      <td>0.38716</td>\n",
       "      <td>0.41725</td>\n",
       "      <td>0.50691</td>\n",
       "      <td>0.38413</td>\n",
       "      <td>0.61237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.29351</td>\n",
       "      <td>0.57591</td>\n",
       "      <td>0.40191</td>\n",
       "      <td>0.60666</td>\n",
       "      <td>0.53842</td>\n",
       "      <td>0.52236</td>\n",
       "      <td>0.55653</td>\n",
       "      <td>0.26194</td>\n",
       "      <td>0.33737</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n6b5405942fb446b</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.45440</td>\n",
       "      <td>0.45144</td>\n",
       "      <td>0.55052</td>\n",
       "      <td>0.64551</td>\n",
       "      <td>0.63833</td>\n",
       "      <td>0.51962</td>\n",
       "      <td>0.34126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.69339</td>\n",
       "      <td>0.44649</td>\n",
       "      <td>0.58797</td>\n",
       "      <td>0.51314</td>\n",
       "      <td>0.42471</td>\n",
       "      <td>0.31818</td>\n",
       "      <td>0.61949</td>\n",
       "      <td>0.66547</td>\n",
       "      <td>0.57674</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ne5d49a5111e84b7</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.64494</td>\n",
       "      <td>0.60252</td>\n",
       "      <td>0.43466</td>\n",
       "      <td>0.60305</td>\n",
       "      <td>0.52179</td>\n",
       "      <td>0.42805</td>\n",
       "      <td>0.59592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19793</td>\n",
       "      <td>0.45149</td>\n",
       "      <td>0.56702</td>\n",
       "      <td>0.31475</td>\n",
       "      <td>0.42197</td>\n",
       "      <td>0.38904</td>\n",
       "      <td>0.59570</td>\n",
       "      <td>0.42558</td>\n",
       "      <td>0.44277</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nd3625b02877d4b2</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.39060</td>\n",
       "      <td>0.62302</td>\n",
       "      <td>0.73704</td>\n",
       "      <td>0.58155</td>\n",
       "      <td>0.42124</td>\n",
       "      <td>0.54693</td>\n",
       "      <td>0.51778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64195</td>\n",
       "      <td>0.22353</td>\n",
       "      <td>0.48502</td>\n",
       "      <td>0.46545</td>\n",
       "      <td>0.52634</td>\n",
       "      <td>0.32485</td>\n",
       "      <td>0.62126</td>\n",
       "      <td>0.51344</td>\n",
       "      <td>0.55221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id   era data_type  feature1  feature2  feature3  feature4  \\\n",
       "0  n221973c37ed247a  era1     train   0.55098   0.42673   0.40180   0.44622   \n",
       "1  n435a06426e694b7  era1     train   0.32694   0.37829   0.38716   0.41725   \n",
       "2  n6b5405942fb446b  era1     train   0.45440   0.45144   0.55052   0.64551   \n",
       "3  ne5d49a5111e84b7  era1     train   0.64494   0.60252   0.43466   0.60305   \n",
       "4  nd3625b02877d4b2  era1     train   0.39060   0.62302   0.73704   0.58155   \n",
       "\n",
       "   feature5  feature6  feature7   ...    feature42  feature43  feature44  \\\n",
       "0   0.68562   0.45346   0.24763   ...      0.55924    0.64714    0.62358   \n",
       "1   0.50691   0.38413   0.61237   ...      0.29351    0.57591    0.40191   \n",
       "2   0.63833   0.51962   0.34126   ...      0.69339    0.44649    0.58797   \n",
       "3   0.52179   0.42805   0.59592   ...      0.19793    0.45149    0.56702   \n",
       "4   0.42124   0.54693   0.51778   ...      0.64195    0.22353    0.48502   \n",
       "\n",
       "   feature45  feature46  feature47  feature48  feature49  feature50  target  \n",
       "0    0.40199    0.51210    0.42287    0.33241    0.54669    0.55408       1  \n",
       "1    0.60666    0.53842    0.52236    0.55653    0.26194    0.33737       1  \n",
       "2    0.51314    0.42471    0.31818    0.61949    0.66547    0.57674       1  \n",
       "3    0.31475    0.42197    0.38904    0.59570    0.42558    0.44277       1  \n",
       "4    0.46545    0.52634    0.32485    0.62126    0.51344    0.55221       0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above statement shows us the first 5 rows of the training data. Here we can see the names of the columns. Take note of the era and data_type columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['era1' 'era2' 'era3' 'era4' 'era5' 'era6' 'era7' 'era8' 'era9' 'era10'\n",
      " 'era11' 'era12' 'era13' 'era14' 'era15' 'era16' 'era17' 'era18' 'era19'\n",
      " 'era20' 'era21' 'era22' 'era23' 'era24' 'era25' 'era26' 'era27' 'era28'\n",
      " 'era29' 'era30' 'era31' 'era32' 'era33' 'era34' 'era35' 'era36' 'era37'\n",
      " 'era38' 'era39' 'era40' 'era41' 'era42' 'era43' 'era44' 'era45' 'era46'\n",
      " 'era47' 'era48' 'era49' 'era50' 'era51' 'era52' 'era53' 'era54' 'era55'\n",
      " 'era56' 'era57' 'era58' 'era59' 'era60' 'era61' 'era62' 'era63' 'era64'\n",
      " 'era65' 'era66' 'era67' 'era68' 'era69' 'era70' 'era71' 'era72' 'era73'\n",
      " 'era74' 'era75' 'era76' 'era77' 'era78' 'era79' 'era80' 'era81' 'era82'\n",
      " 'era83' 'era84' 'era85']\n",
      "['train']\n"
     ]
    }
   ],
   "source": [
    "print(training_data.era.unique())\n",
    "print(training_data.data_type.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above statements we can see all the unique names for eras and data types in our data. In the training data there are 85 eras represented and all data is indeed training data. We can do something similar for the tournament data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>era</th>\n",
       "      <th>data_type</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature42</th>\n",
       "      <th>feature43</th>\n",
       "      <th>feature44</th>\n",
       "      <th>feature45</th>\n",
       "      <th>feature46</th>\n",
       "      <th>feature47</th>\n",
       "      <th>feature48</th>\n",
       "      <th>feature49</th>\n",
       "      <th>feature50</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n00e1d5ebcf3d4d5</td>\n",
       "      <td>era86</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.28523</td>\n",
       "      <td>0.52729</td>\n",
       "      <td>0.60784</td>\n",
       "      <td>0.43518</td>\n",
       "      <td>0.32576</td>\n",
       "      <td>0.63765</td>\n",
       "      <td>0.44005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.35296</td>\n",
       "      <td>0.46170</td>\n",
       "      <td>0.50857</td>\n",
       "      <td>0.40087</td>\n",
       "      <td>0.55512</td>\n",
       "      <td>0.65612</td>\n",
       "      <td>0.60729</td>\n",
       "      <td>0.37915</td>\n",
       "      <td>0.46449</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb0b4cce48b78471</td>\n",
       "      <td>era86</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.38658</td>\n",
       "      <td>0.57589</td>\n",
       "      <td>0.36267</td>\n",
       "      <td>0.36722</td>\n",
       "      <td>0.52405</td>\n",
       "      <td>0.54712</td>\n",
       "      <td>0.63671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26381</td>\n",
       "      <td>0.56040</td>\n",
       "      <td>0.36975</td>\n",
       "      <td>0.50206</td>\n",
       "      <td>0.59444</td>\n",
       "      <td>0.65968</td>\n",
       "      <td>0.42385</td>\n",
       "      <td>0.33500</td>\n",
       "      <td>0.35268</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n7aae3361b330439</td>\n",
       "      <td>era86</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.33371</td>\n",
       "      <td>0.54650</td>\n",
       "      <td>0.49027</td>\n",
       "      <td>0.40156</td>\n",
       "      <td>0.43806</td>\n",
       "      <td>0.47818</td>\n",
       "      <td>0.55603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.34934</td>\n",
       "      <td>0.46677</td>\n",
       "      <td>0.28978</td>\n",
       "      <td>0.63833</td>\n",
       "      <td>0.70284</td>\n",
       "      <td>0.46035</td>\n",
       "      <td>0.49885</td>\n",
       "      <td>0.29836</td>\n",
       "      <td>0.52302</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neca221c2e9374fe</td>\n",
       "      <td>era86</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.29859</td>\n",
       "      <td>0.35833</td>\n",
       "      <td>0.47076</td>\n",
       "      <td>0.38464</td>\n",
       "      <td>0.52346</td>\n",
       "      <td>0.48471</td>\n",
       "      <td>0.55128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.44130</td>\n",
       "      <td>0.55330</td>\n",
       "      <td>0.37002</td>\n",
       "      <td>0.42181</td>\n",
       "      <td>0.45798</td>\n",
       "      <td>0.54207</td>\n",
       "      <td>0.58005</td>\n",
       "      <td>0.48274</td>\n",
       "      <td>0.44154</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nf7f52c87d740439</td>\n",
       "      <td>era86</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.60599</td>\n",
       "      <td>0.69024</td>\n",
       "      <td>0.80057</td>\n",
       "      <td>0.52854</td>\n",
       "      <td>0.43206</td>\n",
       "      <td>0.61740</td>\n",
       "      <td>0.44755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.39515</td>\n",
       "      <td>0.32171</td>\n",
       "      <td>0.62867</td>\n",
       "      <td>0.53641</td>\n",
       "      <td>0.54626</td>\n",
       "      <td>0.67708</td>\n",
       "      <td>0.67124</td>\n",
       "      <td>0.33609</td>\n",
       "      <td>0.44527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id    era   data_type  feature1  feature2  feature3  \\\n",
       "0  n00e1d5ebcf3d4d5  era86  validation   0.28523   0.52729   0.60784   \n",
       "1  nb0b4cce48b78471  era86  validation   0.38658   0.57589   0.36267   \n",
       "2  n7aae3361b330439  era86  validation   0.33371   0.54650   0.49027   \n",
       "3  neca221c2e9374fe  era86  validation   0.29859   0.35833   0.47076   \n",
       "4  nf7f52c87d740439  era86  validation   0.60599   0.69024   0.80057   \n",
       "\n",
       "   feature4  feature5  feature6  feature7   ...    feature42  feature43  \\\n",
       "0   0.43518   0.32576   0.63765   0.44005   ...      0.35296    0.46170   \n",
       "1   0.36722   0.52405   0.54712   0.63671   ...      0.26381    0.56040   \n",
       "2   0.40156   0.43806   0.47818   0.55603   ...      0.34934    0.46677   \n",
       "3   0.38464   0.52346   0.48471   0.55128   ...      0.44130    0.55330   \n",
       "4   0.52854   0.43206   0.61740   0.44755   ...      0.39515    0.32171   \n",
       "\n",
       "   feature44  feature45  feature46  feature47  feature48  feature49  \\\n",
       "0    0.50857    0.40087    0.55512    0.65612    0.60729    0.37915   \n",
       "1    0.36975    0.50206    0.59444    0.65968    0.42385    0.33500   \n",
       "2    0.28978    0.63833    0.70284    0.46035    0.49885    0.29836   \n",
       "3    0.37002    0.42181    0.45798    0.54207    0.58005    0.48274   \n",
       "4    0.62867    0.53641    0.54626    0.67708    0.67124    0.33609   \n",
       "\n",
       "   feature50  target  \n",
       "0    0.46449     1.0  \n",
       "1    0.35268     1.0  \n",
       "2    0.52302     0.0  \n",
       "3    0.44154     1.0  \n",
       "4    0.44527     0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tournament_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we get the first 5 rows of our tournament data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['era86' 'era87' 'era88' 'era89' 'era90' 'era91' 'era92' 'era93' 'era94'\n",
      " 'era95' 'era96' 'era97' 'eraX']\n",
      "['validation' 'test' 'live']\n"
     ]
    }
   ],
   "source": [
    "print(tournament_data.era.unique())\n",
    "print(tournament_data.data_type.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above statements show that the tournament data contains more diverse data types — validation, test, live. The eras contained are from 86 to 97 and some additional one called ‘eraX’. Let’s dig a bit deeper into this with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['era86' 'era87' 'era88' 'era89' 'era90' 'era91' 'era92' 'era93' 'era94'\n",
      " 'era95' 'era96' 'era97']\n",
      "['eraX']\n",
      "['eraX']\n"
     ]
    }
   ],
   "source": [
    "print(tournament_data.era[tournament_data.data_type=='validation'].unique())\n",
    "print(tournament_data.era[tournament_data.data_type=='test'].unique())\n",
    "print(tournament_data.era[tournament_data.data_type=='live'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that the tournament data of the ‘validation’ type contains the eras from 86 to 97 and that the data of type ‘test’ and ‘live’ contain the ‘eraX’ era."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the documentation on the Numerai help page, it is mentioned that the validation data contains the targets (like the training data does). Let’s verify this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.]\n",
      "[ nan]\n",
      "[ nan]\n"
     ]
    }
   ],
   "source": [
    "print(tournament_data.target[tournament_data.data_type=='validation'].unique())\n",
    "print(tournament_data.target[tournament_data.data_type=='test'].unique())\n",
    "print(tournament_data.target[tournament_data.data_type=='live'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation data does indeed contain the targets [0., 1.], whereas the test and live data contain [nan]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we cannot ever have too much training data, combining all the eras into one ‘complete’ training set — training data plus validation data —  is the thing to do. We will therefore disregard the warning made by Numerai:\n",
    "\n",
    "> We recommend you do not train on the validation data even though you have the targets.\n",
    "\n",
    "But, won’t this give us problems with overfitting? Not necessarily, given that we will use cross-validation to test the performance of our neural network models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s create this ‘complete’ training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_data = tournament_data[tournament_data.data_type=='validation']\n",
    "complete_training_data = pd.concat([training_data, validation_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let’s check to see we have the correct eras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['era1', 'era2', 'era3', 'era4', 'era5', 'era6', 'era7', 'era8',\n",
       "       'era9', 'era10', 'era11', 'era12', 'era13', 'era14', 'era15',\n",
       "       'era16', 'era17', 'era18', 'era19', 'era20', 'era21', 'era22',\n",
       "       'era23', 'era24', 'era25', 'era26', 'era27', 'era28', 'era29',\n",
       "       'era30', 'era31', 'era32', 'era33', 'era34', 'era35', 'era36',\n",
       "       'era37', 'era38', 'era39', 'era40', 'era41', 'era42', 'era43',\n",
       "       'era44', 'era45', 'era46', 'era47', 'era48', 'era49', 'era50',\n",
       "       'era51', 'era52', 'era53', 'era54', 'era55', 'era56', 'era57',\n",
       "       'era58', 'era59', 'era60', 'era61', 'era62', 'era63', 'era64',\n",
       "       'era65', 'era66', 'era67', 'era68', 'era69', 'era70', 'era71',\n",
       "       'era72', 'era73', 'era74', 'era75', 'era76', 'era77', 'era78',\n",
       "       'era79', 'era80', 'era81', 'era82', 'era83', 'era84', 'era85',\n",
       "       'era86', 'era87', 'era88', 'era89', 'era90', 'era91', 'era92',\n",
       "       'era93', 'era94', 'era95', 'era96', 'era97'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_training_data.era.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us all eras from 1 to 97, as it is supposed to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create our features (X) and labels(Y) for training our neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [f for f in list(complete_training_data) if \"feature\" in f]\n",
    "X = complete_training_data[features]\n",
    "Y = complete_training_data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature41</th>\n",
       "      <th>feature42</th>\n",
       "      <th>feature43</th>\n",
       "      <th>feature44</th>\n",
       "      <th>feature45</th>\n",
       "      <th>feature46</th>\n",
       "      <th>feature47</th>\n",
       "      <th>feature48</th>\n",
       "      <th>feature49</th>\n",
       "      <th>feature50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.55098</td>\n",
       "      <td>0.42673</td>\n",
       "      <td>0.40180</td>\n",
       "      <td>0.44622</td>\n",
       "      <td>0.68562</td>\n",
       "      <td>0.45346</td>\n",
       "      <td>0.24763</td>\n",
       "      <td>0.61223</td>\n",
       "      <td>0.52564</td>\n",
       "      <td>0.48586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53232</td>\n",
       "      <td>0.55924</td>\n",
       "      <td>0.64714</td>\n",
       "      <td>0.62358</td>\n",
       "      <td>0.40199</td>\n",
       "      <td>0.51210</td>\n",
       "      <td>0.42287</td>\n",
       "      <td>0.33241</td>\n",
       "      <td>0.54669</td>\n",
       "      <td>0.55408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.32694</td>\n",
       "      <td>0.37829</td>\n",
       "      <td>0.38716</td>\n",
       "      <td>0.41725</td>\n",
       "      <td>0.50691</td>\n",
       "      <td>0.38413</td>\n",
       "      <td>0.61237</td>\n",
       "      <td>0.40076</td>\n",
       "      <td>0.52302</td>\n",
       "      <td>0.42932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.46287</td>\n",
       "      <td>0.29351</td>\n",
       "      <td>0.57591</td>\n",
       "      <td>0.40191</td>\n",
       "      <td>0.60666</td>\n",
       "      <td>0.53842</td>\n",
       "      <td>0.52236</td>\n",
       "      <td>0.55653</td>\n",
       "      <td>0.26194</td>\n",
       "      <td>0.33737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.45440</td>\n",
       "      <td>0.45144</td>\n",
       "      <td>0.55052</td>\n",
       "      <td>0.64551</td>\n",
       "      <td>0.63833</td>\n",
       "      <td>0.51962</td>\n",
       "      <td>0.34126</td>\n",
       "      <td>0.57061</td>\n",
       "      <td>0.44524</td>\n",
       "      <td>0.41106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40919</td>\n",
       "      <td>0.69339</td>\n",
       "      <td>0.44649</td>\n",
       "      <td>0.58797</td>\n",
       "      <td>0.51314</td>\n",
       "      <td>0.42471</td>\n",
       "      <td>0.31818</td>\n",
       "      <td>0.61949</td>\n",
       "      <td>0.66547</td>\n",
       "      <td>0.57674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.64494</td>\n",
       "      <td>0.60252</td>\n",
       "      <td>0.43466</td>\n",
       "      <td>0.60305</td>\n",
       "      <td>0.52179</td>\n",
       "      <td>0.42805</td>\n",
       "      <td>0.59592</td>\n",
       "      <td>0.33314</td>\n",
       "      <td>0.48087</td>\n",
       "      <td>0.56990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40814</td>\n",
       "      <td>0.19793</td>\n",
       "      <td>0.45149</td>\n",
       "      <td>0.56702</td>\n",
       "      <td>0.31475</td>\n",
       "      <td>0.42197</td>\n",
       "      <td>0.38904</td>\n",
       "      <td>0.59570</td>\n",
       "      <td>0.42558</td>\n",
       "      <td>0.44277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.39060</td>\n",
       "      <td>0.62302</td>\n",
       "      <td>0.73704</td>\n",
       "      <td>0.58155</td>\n",
       "      <td>0.42124</td>\n",
       "      <td>0.54693</td>\n",
       "      <td>0.51778</td>\n",
       "      <td>0.35616</td>\n",
       "      <td>0.37648</td>\n",
       "      <td>0.51755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.37677</td>\n",
       "      <td>0.64195</td>\n",
       "      <td>0.22353</td>\n",
       "      <td>0.48502</td>\n",
       "      <td>0.46545</td>\n",
       "      <td>0.52634</td>\n",
       "      <td>0.32485</td>\n",
       "      <td>0.62126</td>\n",
       "      <td>0.51344</td>\n",
       "      <td>0.55221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0   0.55098   0.42673   0.40180   0.44622   0.68562   0.45346   0.24763   \n",
       "1   0.32694   0.37829   0.38716   0.41725   0.50691   0.38413   0.61237   \n",
       "2   0.45440   0.45144   0.55052   0.64551   0.63833   0.51962   0.34126   \n",
       "3   0.64494   0.60252   0.43466   0.60305   0.52179   0.42805   0.59592   \n",
       "4   0.39060   0.62302   0.73704   0.58155   0.42124   0.54693   0.51778   \n",
       "\n",
       "   feature8  feature9  feature10    ...      feature41  feature42  feature43  \\\n",
       "0   0.61223   0.52564    0.48586    ...        0.53232    0.55924    0.64714   \n",
       "1   0.40076   0.52302    0.42932    ...        0.46287    0.29351    0.57591   \n",
       "2   0.57061   0.44524    0.41106    ...        0.40919    0.69339    0.44649   \n",
       "3   0.33314   0.48087    0.56990    ...        0.40814    0.19793    0.45149   \n",
       "4   0.35616   0.37648    0.51755    ...        0.37677    0.64195    0.22353   \n",
       "\n",
       "   feature44  feature45  feature46  feature47  feature48  feature49  feature50  \n",
       "0    0.62358    0.40199    0.51210    0.42287    0.33241    0.54669    0.55408  \n",
       "1    0.40191    0.60666    0.53842    0.52236    0.55653    0.26194    0.33737  \n",
       "2    0.58797    0.51314    0.42471    0.31818    0.61949    0.66547    0.57674  \n",
       "3    0.56702    0.31475    0.42197    0.38904    0.59570    0.42558    0.44277  \n",
       "4    0.48502    0.46545    0.52634    0.32485    0.62126    0.51344    0.55221  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    0.0\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Predictions with Keras and scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Using the Keras neural network library for Python we can define some simple neural network model which we can train on our complete training set. First we define the neural network model in a function.\n",
    "\n",
    "Then we create a wrapper for the neural network. This is needed to create a bridge between Keras and scikit-learn. We’ll tell it to run for 10 epochs, with a batch size of 128. Verbosity is set to 0, because we don’t need to see how far the network has been trained.\n",
    "\n",
    "Now, from the Numerai documentation we can learn that:\n",
    "\n",
    "> For cross-validation, it’s better to hold out a random sample of eras rather than a random sample rows. Using a random sample of rows tends to over fit.\n",
    "\n",
    "Therefore, we should use a special cross-validation method called group-k-fold. In our case it is set to do k-fold over the individual eras rather than over the individual rows in the complete training set. We shall use the GroupKFold class from scikit-learn for this. First we create an instance of this class and tell it to create 5 folds. Then using the split method we tell the object to split the training data based on the eras.\n",
    "\n",
    "Using GridSearchCV from scikit-learn we can find good hyper-parameters for our neural network model. Here we try to find out what works best — 10 neurons or 14 and a dropout probability of 0.01 or 0.26. This gives a parameter grid with a total of 4 combinations to try out.\n",
    "\n",
    "Create an instance of  GridSearchCV with the neural network model we defined above, the parameter grid with the 4 combinations, a scoring function that matches the loss function of the neural network, one thread and a verbose level of 2. Then we tell it to fit our training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] dropout=0.01, neurons=10 ........................................\n",
      "[CV]  dropout=0.01, neurons=10, score=-0.6920131037236666, total= 3.1min\n",
      "[CV] dropout=0.01, neurons=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout=0.01, neurons=10, score=-0.6931060224708179, total= 3.1min\n",
      "[CV] dropout=0.01, neurons=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  6.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout=0.01, neurons=10, score=-0.692674851594345, total= 3.1min\n",
      "[CV] dropout=0.01, neurons=10 ........................................\n",
      "[CV]  dropout=0.01, neurons=10, score=-0.6913594624863721, total= 3.1min\n",
      "[CV] dropout=0.01, neurons=10 ........................................\n",
      "[CV]  dropout=0.01, neurons=10, score=-0.6926817816201736, total= 3.1min\n",
      "[CV] dropout=0.01, neurons=14 ........................................\n",
      "[CV]  dropout=0.01, neurons=14, score=-0.6920294021313386, total= 3.1min\n",
      "[CV] dropout=0.01, neurons=14 ........................................\n",
      "[CV]  dropout=0.01, neurons=14, score=-0.6928563954308723, total= 3.1min\n",
      "[CV] dropout=0.01, neurons=14 ........................................\n",
      "[CV]  dropout=0.01, neurons=14, score=-0.6926209476269657, total= 3.1min\n",
      "[CV] dropout=0.01, neurons=14 ........................................\n",
      "[CV]  dropout=0.01, neurons=14, score=-0.6914420946625519, total= 3.0min\n",
      "[CV] dropout=0.01, neurons=14 ........................................\n",
      "[CV]  dropout=0.01, neurons=14, score=-0.693215437551165, total= 3.1min\n",
      "[CV] dropout=0.26, neurons=10 ........................................\n",
      "[CV]  dropout=0.26, neurons=10, score=-0.6918978881932943, total= 3.1min\n",
      "[CV] dropout=0.26, neurons=10 ........................................\n",
      "[CV]  dropout=0.26, neurons=10, score=-0.692150746245305, total= 3.1min\n",
      "[CV] dropout=0.26, neurons=10 ........................................\n",
      "[CV]  dropout=0.26, neurons=10, score=-0.6924042194861828, total= 3.1min\n",
      "[CV] dropout=0.26, neurons=10 ........................................\n",
      "[CV]  dropout=0.26, neurons=10, score=-0.6914966052669476, total= 3.1min\n",
      "[CV] dropout=0.26, neurons=10 ........................................\n",
      "[CV]  dropout=0.26, neurons=10, score=-0.6924782348833339, total= 3.1min\n",
      "[CV] dropout=0.26, neurons=14 ........................................\n",
      "[CV]  dropout=0.26, neurons=14, score=-0.691691016531455, total= 3.1min\n",
      "[CV] dropout=0.26, neurons=14 ........................................\n",
      "[CV]  dropout=0.26, neurons=14, score=-0.6923048289879229, total= 3.1min\n",
      "[CV] dropout=0.26, neurons=14 ........................................\n",
      "[CV]  dropout=0.26, neurons=14, score=-0.6924240843370534, total= 3.1min\n",
      "[CV] dropout=0.26, neurons=14 ........................................\n",
      "[CV]  dropout=0.26, neurons=14, score=-0.6913027613551057, total= 3.1min\n",
      "[CV] dropout=0.26, neurons=14 ........................................\n",
      "[CV]  dropout=0.26, neurons=14, score=-0.6924675837801072, total= 3.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 64.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.692028 using {'dropout': 0.26, 'neurons': 14}\n",
      "-0.692354 (0.000616) with: {'dropout': 0.01, 'neurons': 10}\n",
      "-0.692419 (0.000631) with: {'dropout': 0.01, 'neurons': 14}\n",
      "-0.692078 (0.000360) with: {'dropout': 0.26, 'neurons': 10}\n",
      "-0.692028 (0.000464) with: {'dropout': 0.26, 'neurons': 14}\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_model(neurons=200, dropout=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_shape=(50,), kernel_initializer='glorot_uniform', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer='glorot_normal'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_crossentropy', 'accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=8, batch_size=128, verbose=0)\n",
    "\n",
    "neurons = [10, 14]\n",
    "dropout = [0.01, 0.26]\n",
    "param_grid = dict(neurons=neurons, dropout=dropout)\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "kfold_split = gkf.split(X, Y, groups=complete_training_data.era)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=kfold_split, scoring='neg_log_loss',n_jobs=1, verbose=3)\n",
    "grid_result = grid.fit(X.values, Y.values)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run the fit method of the GridSearchCV object, we are told the following:\n",
    "\n",
    "> Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
    "\n",
    "This means that our neural network will be trained 20 times. For each of the 4 combinations of our parameter grid, 5 different folds of training data will be used. The latter refers to the 5-fold cross validation.\n",
    "\n",
    "Yes, this process takes a long time even with a new high end GPU. On my PC with a Nvidia GTX 1080 GPU every ‘fit’ takes roughly 3.1 min, giving a total of 64.0 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid.best_estimator_.model.save('./my_model_2017-11-07_IV.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_41 (Dense)             (None, 14)                700       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 771\n",
      "Trainable params: 743\n",
      "Non-trainable params: 28\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "grid.best_estimator_.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check the performance for the tournament of the best model found by the GridSearchCV object. Let’s go over the items mentioned in the Numerai documentation:\n",
    "\n",
    "> The leaderboard displayed is based only on validation data. To be on the leaderboard, models are required to have concordance, originality, and consistency.\n",
    "\n",
    "In order for us to earn money in the regular tournament, we need to be on the leaderboard. Hence, our model needs to satisfy the following 3 criteria — concordance, originality and consistency:\n",
    "\n",
    "> Concordance is a measure of whether predictions on the validation set, test set, and live set appear to be generated by the same model.\n",
    "\n",
    "This should not be a problem for our model.\n",
    "\n",
    "> Originality is a measure of whether a set of predictions is uncorrelated with predictions already submitted.\n",
    "\n",
    "This is the most tricky part. If you submit early in the round, then chances are very high that your submission will be original. On the other hand, this probability drops over time. This is why I put values like 0.01 and 0.26 instead 0.0 and 0.25 for the dropout rates in parameter grid. Chances are small that anyone else has these values for their model. This increases the uniqueness of tour model.\n",
    "\n",
    "> Consistency measures the percentage of eras in which a model achieves a logloss < -ln(0.5). … Only models with consistency above 75% are considered consistent.\n",
    "\n",
    "We can check the consistency with our own function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "era86: loss - 0.6902206643444626 consistent: True\n",
      "era87: loss - 0.6870789562210595 consistent: True\n",
      "era88: loss - 0.6924690243949092 consistent: True\n",
      "era89: loss - 0.6919184580327339 consistent: True\n",
      "era90: loss - 0.6882611462892579 consistent: True\n",
      "era91: loss - 0.692048743982823 consistent: True\n",
      "era92: loss - 0.6956388723282587 consistent: False\n",
      "era93: loss - 0.6937774828073401 consistent: False\n",
      "era94: loss - 0.6880148011334818 consistent: True\n",
      "era95: loss - 0.6889040892584941 consistent: True\n",
      "era96: loss - 0.6909991045190831 consistent: True\n",
      "era97: loss - 0.6920358447774848 consistent: True\n",
      "Consistency: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "def check_consistency(model, valid_data):\n",
    "    eras = valid_data.era.unique()\n",
    "    count = 0\n",
    "    count_consistent = 0\n",
    "    for era in eras:\n",
    "        count += 1\n",
    "        current_valid_data = valid_data[validation_data.era==era]\n",
    "        features = [f for f in list(complete_training_data) if \"feature\" in f]\n",
    "        X_valid = current_valid_data[features]\n",
    "        Y_valid = current_valid_data[\"target\"]\n",
    "        loss = model.evaluate(X_valid.values, Y_valid.values, batch_size=128, verbose=0)[0]\n",
    "        if (loss < -np.log(.5)):\n",
    "            consistent = True\n",
    "            count_consistent += 1\n",
    "        else:\n",
    "            consistent = False\n",
    "        print(\"{}: loss - {} consistent: {}\".format(era, loss, consistent))\n",
    "    print (\"Consistency: {}\".format(count_consistent/count))\n",
    "        \n",
    "check_consistency(grid.best_estimator_.model, validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model achieves a consistency above 75%, so our submission passes this criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting the Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll use the following statements to create predictions and write them to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345472/348833 [============================>.] - ETA: 0s\n",
      "Writing predictions to predictions_2017-11-08_14h09m41s.csv\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "x_prediction = tournament_data[features]\n",
    "t_id = tournament_data[\"id\"]\n",
    "y_prediction = grid.best_estimator_.model.predict_proba(x_prediction.values, batch_size=128)\n",
    "\n",
    "results = np.reshape(y_prediction,-1)\n",
    "results_df = pd.DataFrame(data={'probability':results})\n",
    "joined = pd.DataFrame(t_id).join(results_df)\n",
    "\n",
    "\n",
    "# path = \"predictions_w_loss_0_\" + '{:4.0f}'.format(history.history['loss'][-1]*10000) + \".csv\"\n",
    "path = 'predictions_{:}'.format(strftime(\"%Y-%m-%d_%Hh%Mm%Ss\", gmtime())) + '.csv'\n",
    "print()\n",
    "print(\"Writing predictions to \" + path.strip())\n",
    "# # Save the predictions out to a CSV file\n",
    "joined.to_csv(path,float_format='%.15f', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we can upload the CSV file to Numerai and see which score we get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most obvious thing to try now, is of course to change the lists of hyper-parameter values. Perhaps some other values as well, like the number layers in the neural network or the type of optimizer used. You can find some inspiration for this here: https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "\n",
    "For the cross-validation you could try 10-fold cross-validation instead of the 5-fold cross-validation which I showed here. Do take into account that it will take at least twice as long to run. But is the extra running time worth it?\n",
    "\n",
    "Use RandomizedSearchCV from the scikit-learn library instead of GridSearchCV. Or, write your own search function. A reason why you would want to do that, is so that you can save the progress as check-points after every fold. More on that here: https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "\n",
    "Try other machine learning methods like random forests or SVMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/layers/core/\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/cross_validation.html#group-k-fold\n",
    "\n",
    "https://numer.ai/help\n",
    "\n",
    "https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "\n",
    "https://machinelearningmastery.com/check-point-deep-learning-models-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
